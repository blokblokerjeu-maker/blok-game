# ü§ñ Bot BLOK - Q-Learning

## Vue d'ensemble

Ce syst√®me impl√©mente un bot IA pour BLOK utilisant le Q-Learning avec approximation de fonction. Le bot apprend √† jouer en s'entra√Ænant contre lui-m√™me sur des milliers de parties.

## ‚ö° R√®gles BLOK Importantes

Le bot impl√©mente les r√®gles suivantes :

### BLOK (pi√®ces offensives)
- ‚úÖ Se d√©placent de 1-3 cases en avant ou en diagonale
- ‚úÖ Peuvent capturer les BLOK adverses
- ‚úÖ Peuvent sauter par-dessus **leurs propres pi√®ces UNIQUEMENT**
- ‚ùå **NE PEUVENT PAS** sauter par-dessus des pi√®ces adverses (BLOK ou BLOKER)

### BLOKER (pi√®ces d√©fensives - TR√àS PUISSANTES)
- ‚úÖ **T√âL√âPORTATION** : Peuvent se d√©placer sur **N'IMPORTE QUELLE case vide** du plateau (63 destinations possibles !)
- ‚ùå **NE PEUVENT PAS capturer** (ni BLOK ni BLOKER) - Purement d√©fensif
- ‚úÖ Bloquent les mouvements de 2-3 cases des BLOK adverses quand ils sont dans le chemin

### Plateau
- 8x8 cases (64 positions)
- Wrap-around vertical (plateau infini en hauteur)
- Colonnes fixes (a-h, pas de wrap)

### Victoire
- Capturer 4+ BLOK adverses avec au moins 1 d'√©cart
- Syst√®me de "dernier tour" quand un joueur atteint 4 captures

## Architecture

### 1. GameEngine.ts
Moteur de jeu simplifi√© et rapide pour les simulations d'entra√Ænement.
- √âtat du jeu (plateau, pi√®ces, captures)
- Calcul des mouvements l√©gaux
- Ex√©cution des mouvements
- D√©tection de fin de partie

### 2. QLearningAgent.ts
Agent d'apprentissage par renforcement.
- **Approximation de fonction** : Utilise des features pour repr√©senter l'√©tat (plut√¥t qu'une table Q)
- **Epsilon-greedy** : Balance exploration/exploitation
- **TD-Learning** : Mise √† jour des poids via Temporal Difference

### 3. train.ts
Script d'entra√Ænement pour faire jouer le bot contre lui-m√™me.
- Self-play sur N parties
- Sauvegarde p√©riodique des poids
- Statistiques d'entra√Ænement

### 4. BotGame.tsx
Composant React pour jouer contre le bot entra√Æn√©.

## Features utilis√©es

Le bot √©value chaque √©tat avec ces features :

1. **Mat√©riel**
   - `blokAdvantage` : Diff√©rence de BLOK sur le plateau
   - `blokerAdvantage` : Diff√©rence de BLOKER sur le plateau
   - `captureAdvantage` : Diff√©rence de captures

2. **Position**
   - `blokAdvancement` : Progression des BLOK
   - `centerControl` : Contr√¥le du centre
   - `blokProtection` : BLOK prot√©g√©s

3. **Tactique**
   - `threatenedBloks` : BLOK en danger
   - `captureOpportunities` : Opportunit√©s de capture
   - `mobility` : Nombre de mouvements possibles

4. **Strat√©gie**
   - `closeToVictory` : Proximit√© de la victoire
   - `inDanger` : Danger de perdre

## R√©compenses

- **Victoire** : +100
- **D√©faite** : -100
- **Capture d'un BLOK** : +10
- **Mouvement normal** : -0.1 (encourage les parties rapides)

## Utilisation

### √âtape 1 : Installer les d√©pendances

```bash
npm install
npm install -D tsx @types/node
```

### √âtape 2 : Entra√Æner le bot (local)

```bash
# Entra√Ænement sur 1000 parties (recommand√©)
npm run train-bot 1000

# Entra√Ænement rapide (100 parties pour tester)
npm run train-bot 100

# Entra√Ænement intensif (5000 parties pour un bot expert)
npm run train-bot 5000
```

L'entra√Ænement va :
- Cr√©er `bot-training-checkpoints/` avec des sauvegardes tous les 100 jeux
- Cr√©er `bot-training-results/` avec les poids finaux et statistiques

### √âtape 3 : Charger les poids dans le jeu

Apr√®s l'entra√Ænement, charger les poids dans localStorage pour l'utiliser dans l'UI :

```javascript
// Dans la console du navigateur ou dans un script
const fs = require('fs');
const weights = fs.readFileSync('./bot-training-results/agent-black-final.json', 'utf-8');
localStorage.setItem('bot-weights-noir', weights);
```

Ou utilisez le script fourni :

```bash
npm run load-bot-weights
```

### √âtape 4 : Jouer contre le bot

Dans votre composant principal (App.tsx), ajoutez le mode bot :

```tsx
import { BotGame } from './components/BotGame';

// ...
<BotGame playerColor="blanc" onBack={() => setMode('menu')} />
```

## Configuration de l'entra√Ænement

Dans `train.ts`, vous pouvez ajuster :

```typescript
const trainer = new Trainer({
  numGames: 1000,           // Nombre de parties
  saveInterval: 100,        // Sauvegarder tous les N jeux
  maxMovesPerGame: 200,     // Limite de coups (√©vite boucles infinies)
  verbose: false            // Afficher chaque partie
});
```

Dans `QLearningAgent.ts` :

```typescript
new QLearningAgent('blanc', {
  learningRate: 0.2,        // Œ± : Vitesse d'apprentissage
  discountFactor: 0.95,     // Œ≥ : Importance du futur
  explorationRate: 0.5,     // Œµ : Exploration initiale
  explorationDecay: 0.998,  // D√©croissance de Œµ
  minExploration: 0.05      // Œµ minimum
});
```

## Sauvegarder les parties dans Supabase

Pour impl√©menter la sauvegarde des parties :

1. Modifier `train.ts` pour envoyer les parties √† Supabase :

```typescript
import { supabase } from '../lib/supabase';

// Apr√®s chaque partie
await supabase.from('bot_training_games').insert({
  game_number: i,
  winner: result.winner,
  moves: result.moves,
  captures_white: result.capturesWhite,
  captures_black: result.capturesBlack,
  duration_ms: result.duration,
  agent_weights_snapshot: JSON.stringify(agent.getStats().weights)
});
```

2. Cr√©er la table dans Supabase :

```sql
CREATE TABLE bot_training_games (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  game_number INTEGER NOT NULL,
  winner TEXT,
  moves INTEGER NOT NULL,
  captures_white INTEGER NOT NULL,
  captures_black INTEGER NOT NULL,
  duration_ms INTEGER NOT NULL,
  agent_weights_snapshot JSONB,
  created_at TIMESTAMP DEFAULT NOW()
);
```

## Mode "Bot en ligne"

Pour d√©ployer le bot entra√Æn√© :

1. **H√©berger les poids** : Uploader les fichiers JSON des poids sur Supabase Storage
2. **Charger dynamiquement** : Dans BotGame.tsx, charger depuis Supabase au lieu de localStorage
3. **API de jeu** : Cr√©er une fonction edge pour que le bot joue c√¥t√© serveur

```typescript
// Exemple de chargement depuis Supabase
const { data, error } = await supabase.storage
  .from('bot-weights')
  .download('agent-noir-expert.json');

if (data) {
  const weights = await data.text();
  bot.importWeights(weights);
}
```

## Am√©liorer le bot

### 1. Plus d'entra√Ænement
Plus de parties = meilleur bot (recommand√© : 5000-10000 parties)

### 2. Ajuster les hyperparam√®tres
Exp√©rimenter avec diff√©rentes valeurs de Œ±, Œ≥, Œµ

### 3. Ajouter des features
Dans `extractFeatures()`, ajouter :
- Distance moyenne entre BLOK
- Patterns de position (formations)
- Contr√¥le des lignes cl√©s

### 4. Deep Q-Learning (DQN)
Pour un bot encore plus fort, remplacer l'approximation lin√©aire par un r√©seau de neurones

## Performance attendue

Avec 1000 parties d'entra√Ænement :
- **Niveau d√©butant** : Comprend les r√®gles, fait des mouvements coh√©rents
- **Temps d'entra√Ænement** : ~5-10 minutes (d√©pend du CPU)

Avec 5000+ parties :
- **Niveau interm√©diaire** : Strat√©gies de capture, positionnement
- **Temps d'entra√Ænement** : ~30-60 minutes

## D√©bogage

### Le bot fait des mouvements al√©atoires
- V√©rifier que les poids sont charg√©s (`bot.getStats().gamesPlayed` > 0)
- R√©duire `explorationRate` √† 0.05 en mode jeu

### L'entra√Ænement est trop lent
- R√©duire `numGames` pour tester
- D√©sactiver `verbose`
- Augmenter `maxMovesPerGame` si beaucoup de matchs nuls

### Le bot ne s'am√©liore pas
- Augmenter `learningRate`
- V√©rifier les r√©compenses (afficher dans la console)
- Essayer plus de parties

## R√©sultats

Apr√®s l'entra√Ænement, consultez :
- `bot-training-results/training-stats.json` : Statistiques globales
- `bot-training-results/game-results.csv` : D√©tails de chaque partie
- `bot-training-results/agent-*.json` : Poids finaux des agents

## Licence

MIT
